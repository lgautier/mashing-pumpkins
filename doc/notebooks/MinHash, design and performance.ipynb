{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a Python library for building prototypes around MinHash\n",
    "\n",
    "This is very much work-in-progress. May be the software and or ideas presented with be the subject of a peer-reviewed or self-published write-up. For now the URL for this is: https://github.com/lgautier/mashing-pumpkins\n",
    "\n",
    "MinHash in the context of biological sequenced was introduced by the Maryland Bioinformatics Lab [add reference here].\n",
    "\n",
    "Building a MinHash is akin to taking a sample of all k-mers / n-grams found in a sequence and using that sample as a signature or sketch for that sequence.\n",
    "\n",
    "## A look at convenience *vs* performance\n",
    "\n",
    "Moving Python code to C leads to performance improvement... sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sequence\n",
    "\n",
    "First we need a test sequence. Generating a random one quickly can be achieved as follows, for example. If you already have you own way to generate a sequence, or your own benchmark sequence, the following code cell can be changed so as to end up with a variable `sequence` that is a `bytes` object containing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we take a DNA sequence as an example, but this is arbitrary and not necessary.\n",
    "alphabet = b'ATGC'\n",
    "# create a lookup structure to go from byte to 4-mer\n",
    "# (a arbitrary byte is a bitpacked 4-mer)\n",
    "quad = [None,]*(len(alphabet)**4)\n",
    "i = 0\n",
    "for b1 in alphabet:\n",
    "    for b2 in alphabet:\n",
    "        for b3 in alphabet:\n",
    "            for b4 in alphabet:\n",
    "                quad[i] = bytes((b1,b2,b3,b4))\n",
    "                i += 1\n",
    "# random bytes for a 1M genome (order of magnitude for a bacterial genome)\n",
    "import ssl\n",
    "size = int(1E6)\n",
    "sequencebitpacked = ssl.RAND_bytes(int(size/4))\n",
    "sequence = bytearray(int(size))\n",
    "for i, b in zip(range(0, len(sequence), 4), sequencebitpacked):\n",
    "    sequence[i:(i+4)] = quad[b]\n",
    "sequence = bytes(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kicking the tires with `sourmash`\n",
    "\n",
    "The executable `sourmash` is a nice package from the dib-lab implemented in Python and including a library [add reference here]. Perfect for trying out quick what MinHash sketches can do.\n",
    "\n",
    "We will create a MinHash of maximum size 1000 (1000 elements) and of k-mer size 21 (all ngrams of length 21 across the input sequences will be considered for inclusion in the MinHash. At the time of writing MinHash is implemented in C/C++ and use that as a reference for speed, as we measure the time it takes to process our 1M reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.55 seconds\n"
     ]
    }
   ],
   "source": [
    "from sourmash_lib._minhash import MinHash\n",
    "\n",
    "import timeit\n",
    "\n",
    "stmt = \"\"\"\n",
    "smh = MinHash(1000, 21)\n",
    "smh.add_sequence(sequence)\n",
    "\"\"\"\n",
    "t_sourmash = timeit.timeit(stmt,\n",
    "                           setup='from __main__ import sequence, MinHash; sequence=sequence.decode(\"utf-8\")',\n",
    "                           number=5)\n",
    "print(\"%.2f seconds\" % t_sourmash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is awesome. The sketch for a bacteria-sized DNA sequence can be computed very quickly (about a second on my laptop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redisigning it all for convenience and flexibility\n",
    "\n",
    "We have redesigned what a class could look like, and implemented that design in Python\n",
    "foremost for our own convenience and to match the claim of convenience. Now how bad is the impact on performance ?\n",
    "\n",
    "Our new design allows flexibility with respect to the hash function used, and to initially illustrate our point we use `mmh` an existing Python package wrapping MurmurHash3, the hashing function used in `MASH` and `sourmash`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.03 seconds\n",
      "Our Python implementation is 1.31 times slower.\n"
     ]
    }
   ],
   "source": [
    "# make a hashing function to match our design\n",
    "import mmh3\n",
    "def hashfun(sequence, nsize, hbuffer, w=100):\n",
    "    n = min(len(hbuffer), len(sequence)-nsize+1)\n",
    "    for i in range(n):\n",
    "        ngram = sequence[i:(i+nsize)]\n",
    "        hbuffer[i] = mmh3.hash64(ngram)[0]\n",
    "    return n\n",
    "\n",
    "from mashingpumpkins.minhashsketch import MaxHashNgramSketch\n",
    "\n",
    "stmt = 'mhs = MaxHashNgramSketch(21, 1000, hashfun); mhs.add(sequence, hashtype=\"q\")'\n",
    "t_basic = timeit.timeit(stmt,\n",
    "                        setup='from __main__ import MaxHashNgramSketch, hashfun, sequence',\n",
    "                        number=5)\n",
    "print(\"%.2f seconds\" % t_basic)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times slower.\" % (t_basic / t_sourmash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah. Our Python implementation only using `mmh3` and the standard library is not slower.\n",
    "\n",
    "**note: ** the careful reader will not that we have a MaxHash rather than a MinHash. This is so to use algorithms in the Python stan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more to it though. The code in \"mashingpumpkins\" is doing more by keeping track of the k-mer/n-gram along with the hash value in order to allow the generation of inter-operable sketch [add reference to discussion on GitHub]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modifying our class to stop storing the associated k-mer (only keep the hash value) to see if it improves performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98 seconds\n",
      "Our Python implementation is 1.28 times slower.\n"
     ]
    }
   ],
   "source": [
    "class NoNgrams(MaxHashNgramSketch):\n",
    "    \n",
    "    def _make_elt(self, h, ngram):\n",
    "        return (h, )\n",
    "\n",
    "stmt = 'mhs = NoNgrams(21, 1000, hashfun); mhs.add(sequence, hashtype=\"q\")'\n",
    "t_nongrams = timeit.timeit(stmt,\n",
    "                           setup='from __main__ import NoNgrams, hashfun, sequence',\n",
    "                           number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_nongrams)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times slower.\" % (t_nongrams / t_sourmash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real difference here. Storing the k-mers / n-grams only has an impact on the added memory required to stored the 1,000\n",
    "k-mers of length 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our design in computing batches of hash values each time C is reached for MurmurHash3. We have implemented the small C function require to call MurmurHash for several k-mers, and when using it we have interesting performance gains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 seconds\n",
      "Our Python implementation is 3.69 times faster.\n"
     ]
    }
   ],
   "source": [
    "from mashingpumpkins._murmurhash3 import hasharray\n",
    "hashfun = hasharray\n",
    "stmt = 'mhs = MaxHashNgramSketch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_batch = timeit.timeit(stmt,\n",
    "                        setup='from __main__ import MaxHashNgramSketch, hashfun, sequence',\n",
    "                        number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_batch)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash / t_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!\n",
    "\n",
    "At the time of writing this is approximatively 3 times faster than C-implemented `sourmash`. And we are doing more work (we are keeping the ngrams / kmers associated with hash values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have an alternative fast hashing available (XXHash). Slightly faster than MurmurHash3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43 seconds\n",
      "Our Python implementation is 3.57 times faster.\n"
     ]
    }
   ],
   "source": [
    "from mashingpumpkins import _xxhash\n",
    "hashfun = _xxhash.hasharray\n",
    "stmt = 'mhs = MaxHashNgramSketch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_batch_xxh = timeit.timeit(stmt,\n",
    "                            setup='from __main__ import MaxHashNgramSketch, hashfun, sequence',\n",
    "                            number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_batch_xxh)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash / t_batch_xxh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To infinite and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how much time should it take to compute signature for various references ?\n",
    "\n",
    "First we check quickly that the time is roughly proportional to the size of the reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* size: 3,000,000\n",
      "4.87 seconds\n",
      "size ratio: 3.00 - time ratio: 3.15\n",
      "1.12 seconds\n",
      "size ratio: 3.00 - time ratio: 2.69\n",
      "Our Python implementation is 4.33 times faster.\n",
      "\n",
      "* size: 5,000,000\n",
      "8.10 seconds\n",
      "size ratio: 5.00 - time ratio: 5.24\n",
      "1.86 seconds\n",
      "size ratio: 5.00 - time ratio: 4.44\n",
      "Our Python implementation is 4.36 times faster.\n",
      "\n",
      "* size: 10,000,000\n",
      "16.96 seconds\n",
      "size ratio: 10.00 - time ratio: 10.97\n"
     ]
    }
   ],
   "source": [
    "# random genome between 3 and 10 times larger than before\n",
    "\n",
    "for size in (int(3E6), int(5E6), int(1E7), int(2E7)):\n",
    "    print('\\n* size: {:,}'.format(size))\n",
    "    sequencebitpacked = ssl.RAND_bytes(int(size/4))\n",
    "    sequence5 = bytearray(int(size))\n",
    "    for i, b in zip(range(0, len(sequence5), 4), sequencebitpacked):\n",
    "        sequence5[i:(i+4)] = quad[b]\n",
    "    sequence5 = bytes(sequence5)\n",
    "\n",
    "    stmt = \"\"\"\n",
    "smh = MinHash(1000, 21)\n",
    "smh.add_sequence(sequence)\n",
    "    \"\"\"\n",
    "    t_sourmash_5 = timeit.timeit(stmt,\n",
    "                                 setup='from __main__ import sequence5, MinHash; sequence=sequence5.decode(\"utf-8\")',\n",
    "                                 number=5)\n",
    "    print(\"%.2f seconds\" % t_sourmash_5)\n",
    "    print(\"size ratio: %.2f - time ratio: %.2f\" % (len(sequence5)/len(sequence), t_sourmash_5/t_sourmash))\n",
    "\n",
    "    hashfun = hasharray\n",
    "    stmt = 'mhs = MaxHashNgramSketch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "    t_batch_5 = timeit.timeit(stmt,\n",
    "                              setup='from __main__ import MaxHashNgramSketch, hashfun,'\n",
    "                                    'sequence5; sequence=sequence5',\n",
    "                              number=5)\n",
    "    print(\"%.2f seconds\" % t_batch_5)\n",
    "    print(\"size ratio: %.2f - time ratio: %.2f\" % (len(sequence5)/len(sequence), t_batch_5/t_batch))\n",
    "    print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash_5 / t_batch_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time spent appears proportional to the size of the input sequence within than range of sizes... with the suspicion that our code is scaling better with increasing sequence size (relatively faster as the size is increasing).\n",
    "\n",
    "### Back-of-envelope time\n",
    "\n",
    "This would allow us to compute the signatures for >1,800 bacterial genomes per hour and per CPU. On a laptop \n",
    "(where this notebook was initially run). Using the 2 cores, this would be >3,600 bacterial genomes per hour.\n",
    "\n",
    "When considering raw reads from a sequencing run, this would put the 5E11 bases optimally out of a latest\n",
    "Illumina MiSeq sequencer processed on 4 core in about 13 hours. 7 hours on 8 cores. Not great, but quite bearable\n",
    "when an 8-core machine can be rented per hour on cloud for cheap... and this is still in Python so customization\n",
    "and ideas can be implemented rarther easily and quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
