{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a Python library for building prototypes around MinHash\n",
    "\n",
    "This is very much work-in-progress. May be the software and or ideas presented with be the subject of a peer-reviewed or self-published write-up. For now the URL for this is: https://github.com/lgautier/mashing-pumpkins\n",
    "\n",
    "MinHash in the context of biological sequenced was introduced by the Maryland Bioinformatics Lab [add reference here].\n",
    "\n",
    "Building a MinHash is akin to taking a sample of all k-mers / n-grams found in a sequence and using that sample as a signature or sketch for that sequence.\n",
    "\n",
    "## A look at convenience *vs* performance\n",
    "\n",
    "Moving Python code to C leads to performance improvement... sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sequence\n",
    "\n",
    "First we need a test sequence. Generating a random one quickly can be achieved as follows, for example. If you already have you own way to generate a sequence, or your own benchmark sequence, the following code cell can be changed so as to end up with a variable `sequence` that is a `bytes` object containing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we take a DNA sequence as an example, but this is arbitrary and not necessary.\n",
    "alphabet = b'ATGC'\n",
    "# create a lookup structure to go from byte to 4-mer\n",
    "# (a arbitrary byte is a bitpacked 4-mer)\n",
    "quad = [None,]*(len(alphabet)**4)\n",
    "i = 0\n",
    "for b1 in alphabet:\n",
    "    for b2 in alphabet:\n",
    "        for b3 in alphabet:\n",
    "            for b4 in alphabet:\n",
    "                quad[i] = bytes((b1,b2,b3,b4))\n",
    "                i += 1\n",
    "# random bytes for a 1M genome (order of magnitude for a bacterial genome)\n",
    "import ssl\n",
    "size = int(1E6)\n",
    "sequencebitpacked = ssl.RAND_bytes(int(size/4))\n",
    "sequence = bytearray(int(size))\n",
    "for i, b in zip(range(0, len(sequence), 4), sequencebitpacked):\n",
    "    sequence[i:(i+4)] = quad[b]\n",
    "sequence = bytes(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kicking the tires with `sourmash`\n",
    "\n",
    "The executable `sourmash` is a nice package from the dib-lab implemented in Python and including a library [add reference here]. Perfect for trying out quick what MinHash sketches can do.\n",
    "\n",
    "We will create a MinHash of maximum size 1000 (1000 elements) and of k-mer size 21 (all ngrams of length 21 across the input sequences will be considered for inclusion in the MinHash. At the time of writing MinHash is implemented in C/C++ and use that as a reference for speed, as we measure the time it takes to process our 1M reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53 seconds\n"
     ]
    }
   ],
   "source": [
    "from sourmash_lib._minhash import MinHash\n",
    "\n",
    "import timeit\n",
    "\n",
    "stmt = \"\"\"\n",
    "smh = MinHash(1000, 21)\n",
    "smh.add_sequence(sequence)\n",
    "\"\"\"\n",
    "t_sourmash = timeit.timeit(stmt,\n",
    "                           setup='from __main__ import sequence, MinHash; sequence=sequence.decode(\"utf-8\")',\n",
    "                           number=5)\n",
    "print(\"%.2f seconds\" % t_sourmash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is awesome. The sketch for a bacteria-sized DNA sequence can be computed very quickly (less than a second on my laptop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redisigning it all for convenience and flexibility\n",
    "\n",
    "We have redesigned what a class could look like, and implemented that design in Python\n",
    "foremost for our own convenience and to match the claim of convenience. Now how bad is the impact on performance ?\n",
    "\n",
    "Our new design allows flexibility with respect to the hash function used, and to initially illustrate our point we use `mmh` an existing Python package wrapping MurmurHash3, the hashing function used in `MASH` and `sourmash`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 seconds\n",
      "Our Python implementation is 0.90 times slower.\n"
     ]
    }
   ],
   "source": [
    "import mmh3\n",
    "hashfun = mmh3.hash128\n",
    "\n",
    "from mashingpumpkins.minhashsketch import MaxHashNgramSketch\n",
    "\n",
    "stmt = 'mhs = MaxHashNgramSketch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_basic = timeit.timeit(stmt,\n",
    "                        setup='from __main__ import MaxHashNgramSketch, hashfun, sequence',\n",
    "                        number=5)\n",
    "print(\"%.2f seconds\" % t_basic)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times slower.\" % (t_basic / t_sourmash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah. Our Python implementation only using `mmh3` and the standard library is not slower.\n",
    "We will assume that we are faster then.\n",
    "\n",
    "**note: ** the careful reader will not that we have a MaxHash rather than a MinHash. This is so to use algorithms in the Python stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Python implementation is 1.11 times faster.\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash / t_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more to it though. The code in \"mashingpumpkins\" is doing more by keeping track of the k-mer/n-gram along with the hash value in order to allow the generation of inter-operable sketch [add reference to discussion on GitHub]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modifying our class to stop storing the associated k-mer (only keep the hash value) to see if it improves performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37 seconds\n",
      "Our Python implementation is 1.12 times faster.\n"
     ]
    }
   ],
   "source": [
    "class NoNgrams(MaxHashNgramSketch):\n",
    "    \n",
    "    def _make_elt(self, h, ngram):\n",
    "        return (h, )\n",
    "\n",
    "stmt = 'mhs = NoNgrams(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_nongrams = timeit.timeit(stmt,\n",
    "                           setup='from __main__ import NoNgrams, hashfun, sequence',\n",
    "                           number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_nongrams)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash / t_nongrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real difference here. Storing the k-mers / n-grams only has an impact on the added memory required to stored the 1,000\n",
    "k-mers of length 21.\n",
    "\n",
    "The flexibility of our design comes from code modularity, and nested function calls can often have worse performances than inlined code. We inlined our code to observe the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30 seconds\n",
      "Our Python implementation is 1.18 times faster.\n"
     ]
    }
   ],
   "source": [
    "from heapq import heappush, heapreplace\n",
    "\n",
    "class NoNgramsAndInlined(MaxHashNgramSketch):\n",
    "    \"\"\"\n",
    "    Just like MaxHashNgramSketch but the method `add()` has all calls to other methods inlined.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def add(self, s):\n",
    "        hashfun = self._hashfun\n",
    "        heap = self._heap\n",
    "        maxsize = self._maxsize\n",
    "        nsize = self._nsize\n",
    "        heapset = self._heapset\n",
    "        i = None\n",
    "        lheap = len(heap)\n",
    "        if lheap > 0:\n",
    "            heaptop = heap[0]\n",
    "        else:\n",
    "            heaptop = None\n",
    "        for i in range(0, len(s)-nsize):\n",
    "            ngram = s[i:(i+nsize)]\n",
    "            h = hashfun(ngram)\n",
    "            if lheap < maxsize:\n",
    "                elt = h\n",
    "                if elt not in heapset:\n",
    "                    heapset.add(elt)\n",
    "                    heappush(heap, elt)\n",
    "                    heaptop = heap[0]\n",
    "                    lheap += 1\n",
    "            elif h  > heaptop:\n",
    "                elt = h\n",
    "                if elt not in heapset:\n",
    "                    heapset = heapset\n",
    "                    heapset.add(elt)\n",
    "                    out = heapreplace(heap, elt)\n",
    "                    heapset.remove(out)\n",
    "                    heaptop = heap[0]\n",
    "        if i is not None:\n",
    "             self._nvisited += (i+1)    \n",
    "\n",
    "import timeit\n",
    "stmt = 'mhs = NoNgramsAndInlined(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_nongrams_inlined = timeit.timeit(stmt,\n",
    "                                   setup='from __main__ import NoNgramsAndInlined, hashfun, sequence',\n",
    "                                   number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_nongrams_inlined)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash / t_nongrams_inlined))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very marginal improvement, if significant at all, but arguably not really worth the trouble and the loss of flexibility.\n",
    "\n",
    "The inlining is letting us explore and other idea though. Computing batches of hash values each time C is reached for MurmurHash3. We have implemented the small C function require to call MurmurHash for several k-mers, and our inlined implementation is easy to modify to take advantage of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 seconds\n",
      "Our Python implementation is 3.10 times faster.\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "\n",
    "class NoNgramsAndInlinedAndBatch(MaxHashNgramSketch):\n",
    "    \"\"\"\n",
    "    Just like MaxHashNgramSketch but the method `add()` has all calls to other methods inlined.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def add(self, s, w=100):\n",
    "        hashfun = self._hashfun\n",
    "        heap = self._heap\n",
    "        maxsize = self._maxsize\n",
    "        nsize = self._nsize\n",
    "        heapset = self._heapset\n",
    "        i = None\n",
    "        lheap = len(heap)\n",
    "        hashbuffer = array.array('Q', [0,]*w)\n",
    "        if lheap > 0:\n",
    "            heaptop = heap[0]\n",
    "        else:\n",
    "            heaptop = None\n",
    "        \n",
    "        for i in range(0, len(s)-nsize, w):\n",
    "            subs = s[i:(i+w)]\n",
    "            nsubs = hashfun(subs, nsize, hashbuffer)\n",
    "            for j in range(w):\n",
    "                h = hashbuffer[j]\n",
    "                if lheap < maxsize:\n",
    "                    elt = h\n",
    "                    if elt not in heapset:\n",
    "                        heapset.add(elt)\n",
    "                        heappush(heap, elt)\n",
    "                        heaptop = heap[0]\n",
    "                        lheap += 1\n",
    "                elif h  > heaptop:\n",
    "                    elt = h\n",
    "                    if elt not in heapset:\n",
    "                        heapset = heapset\n",
    "                        heapset.add(elt)\n",
    "                        out = heapreplace(heap, elt)\n",
    "                        heapset.remove(out)\n",
    "                        heaptop = heap[0]\n",
    "        if i is not None:\n",
    "             self._nvisited += (i+1)    \n",
    "\n",
    "from mashingpumpkins._murmurhash3 import hasharray\n",
    "hashfun = hasharray\n",
    "stmt = 'mhs = NoNgramsAndInlinedAndBatch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "t_batch = timeit.timeit(stmt,\n",
    "                        setup='from __main__ import NoNgramsAndInlinedAndBatch, hashfun, sequence',\n",
    "                        number=5)\n",
    "\n",
    "print(\"%.2f seconds\" % t_batch)\n",
    "\n",
    "print(\"Our Python implementation is %.2f times faster.\" % (t_nongrams_inlined / t_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. At the time of writing this is approximatively 3 times faster than C-implemented `sourmash`.\n",
    "\n",
    "The next iteration on the design will include this, and will hopefully significantly faster than the original while\n",
    "continuing to provide flexibility for research and prototypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To infinite and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how much time should it take to compute signature for various references ?\n",
    "\n",
    "First we check quickly that the time is roughly proportional to the size of the reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* size: 3,000,000\n",
      "4.47 seconds\n",
      "size ratio: 3.00 - time ratio: 2.92\n",
      "1.21 seconds\n",
      "size ratio: 3.00 - time ratio: 2.87\n",
      "Our Python implementation is 3.70 times faster.\n",
      "\n",
      "* size: 5,000,000\n",
      "7.42 seconds\n",
      "size ratio: 5.00 - time ratio: 4.84\n",
      "2.10 seconds\n",
      "size ratio: 5.00 - time ratio: 5.00\n",
      "Our Python implementation is 3.53 times faster.\n",
      "\n",
      "* size: 10,000,000\n"
     ]
    }
   ],
   "source": [
    "# random genome between 3 and 10 times larger than before\n",
    "\n",
    "for size in (int(3E6), int(5E6), int(10E6)):\n",
    "    print('\\n* size: {:,}'.format(size))\n",
    "    sequencebitpacked = ssl.RAND_bytes(int(size/4))\n",
    "    sequence5 = bytearray(int(size))\n",
    "    for i, b in zip(range(0, len(sequence5), 4), sequencebitpacked):\n",
    "        sequence5[i:(i+4)] = quad[b]\n",
    "    sequence5 = bytes(sequence5)\n",
    "\n",
    "    stmt = \"\"\"\n",
    "smh = MinHash(1000, 21)\n",
    "smh.add_sequence(sequence)\n",
    "    \"\"\"\n",
    "    t_sourmash_5 = timeit.timeit(stmt,\n",
    "                                 setup='from __main__ import sequence5, MinHash; sequence=sequence5.decode(\"utf-8\")',\n",
    "                                 number=5)\n",
    "    print(\"%.2f seconds\" % t_sourmash_5)\n",
    "    print(\"size ratio: %.2f - time ratio: %.2f\" % (len(sequence5)/len(sequence), t_sourmash_5/t_sourmash))\n",
    "\n",
    "    hashfun = hasharray\n",
    "    stmt = 'mhs = NoNgramsAndInlinedAndBatch(21, 1000, hashfun); mhs.add(sequence)'\n",
    "    t_batch_5 = timeit.timeit(stmt,\n",
    "                              setup='from __main__ import NoNgramsAndInlinedAndBatch, hashfun,'\n",
    "                                    'sequence5; sequence=sequence5',\n",
    "                              number=5)\n",
    "    print(\"%.2f seconds\" % t_batch_5)\n",
    "    print(\"size ratio: %.2f - time ratio: %.2f\" % (len(sequence5)/len(sequence), t_batch_5/t_batch))\n",
    "    print(\"Our Python implementation is %.2f times faster.\" % (t_sourmash_5 / t_batch_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time spent appears proportional to the size of the input sequence within than range of sizes.\n",
    "\n",
    "### Back-of-envelope time\n",
    "\n",
    "This would allow us to compute the signatures for >1,800 bacterial genomes per hour and per CPU. On a laptop \n",
    "(where this notebook was initially run). Using the 2 cores, this would be >3,600 bacterial genomes per hour.\n",
    "\n",
    "When considering raw reads from a sequencing run, this would put the 5E11 bases optimally out of a latest\n",
    "Illumina MiSeq sequencer processed on 4 core in about 13 hours. 7 hours on 8 cores. Not great, but quite bearable\n",
    "when an 8-core machine can be rented per hour on cloud for cheap... and this is still in Python so customization\n",
    "and ideas can be implemented rarther easily and quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
